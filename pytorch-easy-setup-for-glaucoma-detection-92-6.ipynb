{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7802508,"sourceType":"datasetVersion","datasetId":4154884}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time\nimport copy\nfrom tqdm import tqdm\nimport random\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T00:50:25.793363Z","iopub.execute_input":"2024-05-16T00:50:25.793711Z","iopub.status.idle":"2024-05-16T00:50:31.787245Z","shell.execute_reply.started":"2024-05-16T00:50:25.793683Z","shell.execute_reply":"2024-05-16T00:50:31.786226Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class AddNoise(object):\n    def __init__(self, noise_level):\n        self.noise_level = noise_level\n        \n    def __call__(self, img):\n        img_tensor = transforms.functional.to_tensor(img)\n        noise = torch.rand_like(img_tensor) * self.noise_level\n        noisy_img = img_tensor + noise\n        return transforms.functional.to_pil_image(noisy_img)\n    \n# Applying Transforms to the Data\nSIZE = 512\nCOLOR_DEVIATION = 0.01\nimage_transforms = { \n    'train': transforms.Compose([\n        transforms.Resize(size=SIZE),\n        AddNoise(0.01),\n        transforms.ColorJitter(brightness=(1.0-COLOR_DEVIATION,1.0+COLOR_DEVIATION),contrast=(1.0-COLOR_DEVIATION,1.0+COLOR_DEVIATION),saturation=(1.0-COLOR_DEVIATION,1.0+COLOR_DEVIATION),hue=(-1*COLOR_DEVIATION,COLOR_DEVIATION)),\n        transforms.RandomRotation(degrees=0),\n        transforms.RandomAffine(degrees=0),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]),\n    'validation': transforms.Compose([\n        transforms.Resize(size=SIZE),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(size=SIZE),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-16T00:50:31.789047Z","iopub.execute_input":"2024-05-16T00:50:31.790265Z","iopub.status.idle":"2024-05-16T00:50:31.801213Z","shell.execute_reply.started":"2024-05-16T00:50:31.790226Z","shell.execute_reply":"2024-05-16T00:50:31.800267Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set train and valid directory paths\nroot = '/kaggle/input/glaucoma-dataset-eyepacs-airogs-light-v2/eyepac-light-v2-512-jpg/'\ntrain_directory = root + 'train'\ntest_directory = root + 'test'\nvalidation_directory = root + 'validation'\n\n# batch size\nbatch_size = 4\n\n# Load Data from folders\ndata = {\n    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n    'validation': datasets.ImageFolder(root=validation_directory, transform=image_transforms['validation']),\n    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n}\n\n# Size of Data, to be used for calculating Average Loss and Accuracy\ntrain_data_size = len(data['train'])\nvalidation_data_size = len(data['validation'])\ntest_data_size = len(data['test'])\n\n# Create iterators for the Data loaded using DataLoader module\ntrain_data = DataLoader(data['train'], batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)\nvalidation_data = DataLoader(data['validation'], batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\ntest_data = DataLoader(data['test'], batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n\n# Print the train, validation and test set data sizes\ntrain_data_size, validation_data_size, test_data_size","metadata":{"execution":{"iopub.status.busy":"2024-05-16T00:50:32.222596Z","iopub.execute_input":"2024-05-16T00:50:32.223372Z","iopub.status.idle":"2024-05-16T00:50:36.461474Z","shell.execute_reply.started":"2024-05-16T00:50:32.223336Z","shell.execute_reply":"2024-05-16T00:50:36.460612Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(8000, 770, 770)"},"metadata":{}}]},{"cell_type":"code","source":"# load pretrained model\nmodel_ft = models.mobilenet_v3_large(weights=torchvision.models.MobileNet_V3_Large_Weights.DEFAULT, progress=True)\nmodel_ft.classifier[-1] = nn.Linear(1280, 2)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel_ft = model_ft.to(device)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n\n# Decay LR by a factor of 0.1 every 2 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T00:50:40.132098Z","iopub.execute_input":"2024-05-16T00:50:40.132777Z","iopub.status.idle":"2024-05-16T00:50:40.821013Z","shell.execute_reply.started":"2024-05-16T00:50:40.132733Z","shell.execute_reply":"2024-05-16T00:50:40.820091Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n100%|██████████| 21.1M/21.1M [00:00<00:00, 114MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the number of parameters\ntotal_params = sum(p.numel() for p in model_ft.parameters())\nprint(\"Total number of parameters: \", total_params)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T00:50:40.822517Z","iopub.execute_input":"2024-05-16T00:50:40.822823Z","iopub.status.idle":"2024-05-16T00:50:40.829246Z","shell.execute_reply.started":"2024-05-16T00:50:40.822797Z","shell.execute_reply":"2024-05-16T00:50:40.828201Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Total number of parameters:  4204594\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n        \n        # Create a progress bar for the epoch\n        epoch_progress = tqdm(total=len(train_data), desc=f'Epoch {epoch}/{num_epochs - 1}', position=0, leave=True)\n        \n        for phase in ['train', 'validation']:\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Set model mode\n            if phase == 'train':\n                model.train()\n                dataloader = train_data\n            else:\n                model.eval()\n                dataloader = validation_data\n\n            # Iterate over data\n            for inputs, labels in dataloader:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n                # Update progress bar\n                epoch_progress.set_postfix(phase=phase, loss=running_loss / len(data[phase]), acc=running_corrects.double() / len(data[phase]))\n                epoch_progress.update()\n\n            # Adjust learning rate\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / len(data[phase])\n            epoch_acc = running_corrects.double() / len(data[phase])\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # Update best accuracy\n            if phase == 'validation' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        epoch_progress.close()\n\n    # Test the model\n    model.load_state_dict(best_model_wts)\n    model.eval()\n    test_corrects = 0\n\n    for inputs, labels in test_data:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            test_corrects += torch.sum(preds == labels.data)\n\n    test_acc = test_corrects.double() / test_data_size\n    print('Test Accuracy: {:.4f}'.format(test_acc))\n\n    return model\n\n# Train the model\nmodel_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=6)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T00:50:51.586847Z","iopub.execute_input":"2024-05-16T00:50:51.587192Z","iopub.status.idle":"2024-05-16T01:33:46.392805Z","shell.execute_reply.started":"2024-05-16T00:50:51.587167Z","shell.execute_reply":"2024-05-16T01:33:46.391641Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 0/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0/5: 100%|██████████| 2000/2000 [07:34<00:00,  4.50it/s, acc=tensor(0.7662, device='cuda:0', dtype=torch.float64), loss=0.498, phase=train]  ","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.4978 Acc: 0.7662\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0/5: 2193it [07:45,  4.71it/s, acc=tensor(0.8143, device='cuda:0', dtype=torch.float64), loss=0.412, phase=validation]                            \n","output_type":"stream"},{"name":"stdout","text":"validation Loss: 0.4124 Acc: 0.8143\nEpoch 1/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 2000/2000 [06:50<00:00,  4.73it/s, acc=tensor(0.8648, device='cuda:0', dtype=torch.float64), loss=0.33, phase=train] ","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3302 Acc: 0.8648\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5: 2193it [06:57,  5.25it/s, acc=tensor(0.8883, device='cuda:0', dtype=torch.float64), loss=0.263, phase=validation]                             \n","output_type":"stream"},{"name":"stdout","text":"validation Loss: 0.2628 Acc: 0.8883\nEpoch 2/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 2000/2000 [06:57<00:00,  4.84it/s, acc=tensor(0.8819, device='cuda:0', dtype=torch.float64), loss=0.292, phase=train]","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.2916 Acc: 0.8819\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 2193it [07:04,  5.17it/s, acc=tensor(0.9065, device='cuda:0', dtype=torch.float64), loss=0.239, phase=validation]                            \n","output_type":"stream"},{"name":"stdout","text":"validation Loss: 0.2385 Acc: 0.9065\nEpoch 3/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 2000/2000 [06:52<00:00,  4.90it/s, acc=tensor(0.9206, device='cuda:0', dtype=torch.float64), loss=0.204, phase=train] ","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.2041 Acc: 0.9206\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 2193it [06:59,  5.23it/s, acc=tensor(0.9286, device='cuda:0', dtype=torch.float64), loss=0.19, phase=validation]                              \n","output_type":"stream"},{"name":"stdout","text":"validation Loss: 0.1900 Acc: 0.9286\nEpoch 4/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 2000/2000 [06:51<00:00,  4.78it/s, acc=tensor(0.9311, device='cuda:0', dtype=torch.float64), loss=0.18, phase=train]  ","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1804 Acc: 0.9311\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 2193it [06:58,  5.24it/s, acc=tensor(0.9351, device='cuda:0', dtype=torch.float64), loss=0.194, phase=validation]                             \n","output_type":"stream"},{"name":"stdout","text":"validation Loss: 0.1943 Acc: 0.9351\nEpoch 5/5\n----------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 2000/2000 [06:52<00:00,  4.78it/s, acc=tensor(0.9326, device='cuda:0', dtype=torch.float64), loss=0.176, phase=train] ","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1764 Acc: 0.9326\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 2193it [06:59,  5.23it/s, acc=tensor(0.9325, device='cuda:0', dtype=torch.float64), loss=0.187, phase=validation]                             \n","output_type":"stream"},{"name":"stdout","text":"validation Loss: 0.1875 Acc: 0.9325\nTest Accuracy: 0.9221\n","output_type":"stream"}]},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=3)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T01:36:01.392592Z","iopub.execute_input":"2024-05-16T01:36:01.393028Z","iopub.status.idle":"2024-05-16T01:57:11.283291Z","shell.execute_reply.started":"2024-05-16T01:36:01.392988Z","shell.execute_reply":"2024-05-16T01:57:11.282108Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 0/2\n----------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0/2: 100%|██████████| 2000/2000 [06:47<00:00,  5.02it/s, acc=tensor(0.9390, device='cuda:0', dtype=torch.float64), loss=0.163, phase=train] ","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1632 Acc: 0.9390\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0/2: 2193it [06:54,  5.29it/s, acc=tensor(0.9351, device='cuda:0', dtype=torch.float64), loss=0.191, phase=validation]                             \n","output_type":"stream"},{"name":"stdout","text":"validation Loss: 0.1909 Acc: 0.9351\nEpoch 1/2\n----------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2: 100%|██████████| 2000/2000 [06:57<00:00,  4.70it/s, acc=tensor(0.9370, device='cuda:0', dtype=torch.float64), loss=0.163, phase=train] ","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1626 Acc: 0.9370\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/2: 2193it [07:04,  5.17it/s, acc=tensor(0.9364, device='cuda:0', dtype=torch.float64), loss=0.187, phase=validation]                             \n","output_type":"stream"},{"name":"stdout","text":"validation Loss: 0.1870 Acc: 0.9364\nEpoch 2/2\n----------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/2: 100%|██████████| 2000/2000 [06:56<00:00,  4.95it/s, acc=tensor(0.9386, device='cuda:0', dtype=torch.float64), loss=0.162, phase=train] ","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1618 Acc: 0.9386\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/2: 2193it [07:03,  5.18it/s, acc=tensor(0.9351, device='cuda:0', dtype=torch.float64), loss=0.186, phase=validation]                             ","output_type":"stream"},{"name":"stdout","text":"validation Loss: 0.1865 Acc: 0.9351\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.9260\n","output_type":"stream"}]}]}